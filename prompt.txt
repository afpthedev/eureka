Türk Borsasında Hisse Senedi Tahmin Platformu Tasarımı
Türk borsasında işlem gören hisse senetlerinin gelecekteki performansını tahmin eden platform, Spring Boot tabanlı bir Backend, Flask tabanlı Python makine öğrenmesi servisi ve PostgreSQL veritabanı bileşenlerinden oluşan modüler bir mimariye sahip olacaktır. Tüm bileşenler Docker Compose ile tek bir ortamda çalıştırılacak, bu da kolay dağıtım ve ölçeklenebilirlik sağlayacaktır. Aşağıda, projenin bileşenleri ve gereksinimleri ayrıntılı şekilde ele alınmıştır.
Makine Öğrenmesi Modelleri
Platform, esnek bir makine öğrenimi altyapısına sahip olacak ve çeşitli model türlerini destekleyecektir. İlk aşamada sistemin uçtan uca çalışmasını görmek amacıyla dummy (basit/sabit) tahminler üretilecek, ancak mimari tasarım daha karmaşık modellere geçişe hazır olacaktır. Desteklenecek başlıca model türleri şunlardır:
Zaman Serisi Modelleri: ARIMA, LSTM gibi zaman serisi tahmininde kullanılan modeller ile hisse senedi fiyatlarının geçmişine dayalı gelecek değer tahminleri.
Makine Öğrenmesi/Derin Öğrenme Modelleri: XGBoost, Random Forest, Logistic Regression gibi algoritmalar ile özniteliklere dayalı tahminler.
Diğer Modeller: İhtiyaca göre SVM, Prophet vb. diğer yöntemler de entegre edilebilir.
Model seçimi dinamik ve kolay genişletilebilir olacak şekilde tasarlanacaktır. Örneğin, Python servisinde her model türü için ayrı bir sınıf veya fonksiyon tanımlanabilir ve model seçimi bir konfigürasyon parametresiyle veya tahmin isteğinin türüne göre belirlenebilir. Bu sayede yeni bir model eklendiğinde mevcut sistemde minimum değişiklikle entegre edilebilir. İlk etapta dummy model olarak, örneğin "son değeri tekrarlama" veya rastgele bir değişim yüzdesi ekleme gibi basit bir yöntem kullanılabilir. Bu, sistem entegrasyonunun test edilmesini sağlar. Ardından, veriler biriktikçe ve sistem olgunlaştıkça, eğitimli LSTM modelleri veya diğer gelişmiş algoritmalar devreye alınacaktır. Model eğitimi platformun bir parçası olarak planlanabilir; örneğin, günlük kapanış verileriyle LSTM modelini periyodik olarak yeniden eğitmek ve böylece modeli güncel tutmak mümkün olacaktır.
Veri Kaynağı ve Veri Akışı
Hisse senedi fiyat verileri Türkiye Cumhuriyet Merkez Bankası (TCMB)’nin sağladığı API üzerinden alınacak. TCMB’nin Elektronik Veri Dağıtım Sistemi (EVDS) gibi servisleri kullanılarak Borsa İstanbul’daki hisse senetlerinin tarihsel fiyat verilerine düzenli erişim sağlanabilir. Bu veri entegrasyonunun özellikleri:
API Entegrasyonu: TCMB API’sine erişim için gerekli anahtar ve kimlik doğrulama adımları tamamlanacak. Belirli bir hisse senedine ait tarihsel fiyat serisi, istenen periyotlarla (örneğin günlük kapanış fiyatları) API çağrılarıyla çekilecek.
Düzenli Veri Akışı: Veri çekme işlemi periyodik olarak gerçekleştirilecek. Örneğin, her iş günü kapanışında veya her saat başı yeni veriler kontrol edilerek sistemin veri havuzu güncellenecek. Bu işlem için Spring Boot içinde @Scheduled anotasyonlu işler tanımlanabilir ya da ayrı bir veri toplama servisi düşünülebilir.
Veri İşleme: API’den alınan ham veriler modele uygun hale getirilecek. Tarih formatları, eksik veriler, kapalı günler vs. işlenerek veride tutarlılık sağlanacak. Gerektiğinde veriler normalleştirilecek veya ek finansal öznitelikler (hareketli ortalamalar, oynaklık gibi) hesaplanacak.
Veritabanına Kayıt: Alınan veri hem anlık tahminlerde kullanılmak hem de geçmiş verinin saklanması için PostgreSQL veritabanında tutulacak. Örneğin, hisse_fiyatlari adında bir tablo ile her hisse senedinin tarihsel fiyatları saklanabilir (tarih, açılış, kapanış, hacim gibi kolonlarla).
Veri Erişimi: Makine öğrenmesi modeli tahmin yaparken gerekli veriyi ya doğrudan TCMB API’sinden çekecek ya da daha verimli olması için veritabanından alacak. Daha iyi performans için, Python servisinin ihtiyaç duyacağı son N gündeki veriler önceden veritabanında hazır tutulabilir. Bu sayede her tahmin isteğinde API’ye çağrı yapmaya gerek kalmaz, sistem kendi verisinden beslenir.
Bu yaklaşım, gerçek zamanlı ve doğru verinin modele iletilmesini sağlar. Veri akışı otomatik olduğundan, sistem değişen piyasa koşullarına göre en güncel bilgiyi kullanarak tahmin üretir. Ayrıca ham verilerin saklanması, gelecekte farklı modelleri eğitmek veya geçmiş tahminlerin doğruluğunu ölçmek açısından da önemlidir.
Backend Katmanı (Spring Boot)
Projenin sunucu tarafı mantığını ve istemciye sunulan API’leri yöneten Spring Boot tabanlı bir Backend uygulaması olacaktır. Bu uygulama, RESTful servisler sağlayacak ve temiz, modüler bir mimari için üç temel katmana ayrılacaktır:
Controller Katmanı: Dış dünyaya açılan HTTP endpoint’lerinin tanımlandığı katmandır. Örneğin, GET /api/tahmin?sembol=GARAN gibi bir isteği karşılayıp işlemek için bir controller metodu yazılacaktır. Controller sadece gelen istek parametrelerini alır, doğrular ve işlemek üzere Service katmanına iletir. Sonuç olarak da Service’den dönen tahmin sonucunu HTTP cevabı olarak istemciye iletir. Bu katmanda mümkün olduğunca iş mantığı barındırılmaz, böylece kod okunabilirliği artar ve test etmek kolaylaşır.
Service Katmanı (Facade): İş mantığının ve farklı bileşenler arası koordinasyonun gerçekleştiği katmandır. Bu projede Service katmanı aynı zamanda bir Facade Pattern uygulaması olacaktır. Facade, arka planda birden fazla işi (veritabanı okuma/yazma, başka servise istek yapma gibi) yaparak bunları tek bir noktadan kontrol eder. Örneğin, TahminService sınıfı bir hisse sembolü alarak:
Gerekli ise veritabanından ilgili hissenin son bilinen verilerini çeker.
Python makine öğrenmesi servisine REST çağrısı yaparak tahmin ister.
Gelen tahmin sonucunu alıp veritabanına kaydeder.
Tahmin sonucunu Controller’a döndürür.
Bu akışın tümünü Service katmanı üstlenir ve Controller bu detayları bilmez. Böylece ileride tahmin mantığında değişiklik yapılsa bile (örneğin tahmin için kullanılacak servis veya yöntem değişse de) Controller katmanı etkilenmez; sadece Service (Facade) güncellenir. Bu da bakımı kolaylaştırır.
Repository Katmanı: Veritabanı işlemlerinin soyutlandığı katmandır. Spring Boot uygulaması JPA veya JDBC kullanarak PostgreSQL veritabanına bağlanır. JPA kullanımı tercih edilirse, her tabloya karşılık bir Entity sınıfı ve ona ait bir Repository arayüzü tanımlanır. Örneğin, TahminSonucu adında bir entity (içinde sembol, tahmin edilen değer, tarih, model türü vb. alanlarla) ve TahminSonucuRepository gibi bir arayüz ile temel CRUD işlemleri otomatik sağlanır. Repository katmanı sayesinde Service katmanı doğrudan SQL yazmak zorunda kalmaz, veritabanı işlemlerini bu arayüz üzerinden yapar. Bu da SQL Injection riskini azaltır ve kodun düzenli olmasını sağlar.
Backend uygulamasında ayrıca DTO (Data Transfer Object) modelleri ve gerekli dönüşümler de bulunabilir. Örneğin, veritabanı entity’si ile API üzerinden dönen cevap birebir aynı olmak zorunda değildir; bir Mapper yardımıyla entity verisinden bir cevap DTO’su oluşturulabilir. Bu sayede istemciye gereksiz bilgiler sunulmaz ve versiyonlama/yapısal değişiklikler daha kolay yönetilir. Spring Boot projesi içinde konfigurasyon değerleri (örneğin Python servisin URL’i, veritabanı bağlantı bilgileri, API anahtarları gibi) application.yml veya application.properties dosyalarında tutulacak. Bu değerler Docker ortam değişkenleri ile override edilebilecek şekilde ayarlanır (özellikle hassas bilgiler ortama çekilir, koda sabitlenmez). Ayrıca, Backend gerekli olduğunda asenkron işlemler veya kuyruk mekanizmaları da kullanabilir (örneğin tahmin isteklerini kuyruklayıp işlemek gibi), fakat ilk etapta doğrudan istek/cevap şeklinde senkron bir yapı yeterli olacaktır. Önemli olan, Spring Boot tarafının yalın, modüler ve test edilebilir bir yapıda olmasıdır.
Makine Öğrenmesi Servisi (Python/Flask)
Makine öğrenmesi işlemlerini gerçekleştirecek ayrı bir servis, Python dilinde geliştirilecek ve hafif bir web çatısı olan Flask ile bir REST API sunacaktır. Bu servis, model tahminlerini gerçekleştirip sonuçları JSON formatında geri dönecek şekilde tasarlanacaktır. Ana özellikleri şöyle olacaktır:
REST API Endpoint’leri: Örneğin /predict adında bir endpoint tanımlanabilir. Bu endpoint, HTTP POST isteği ile çağrıldığında istek gövdesinde veya sorgu parametresinde belirtilen hisse senedi sembolüne (ve muhtemel diğer parametrelere, örneğin tahmin edilecek ileri tarih aralığına) göre tahmin yapacaktır. Basitlik için, ilk aşamada tek bir endpoint ile tüm işlemi yapmak mümkün. İleride farklı modeller veya farklı tahmin türleri (kısa vade/uzun vade gibi) için birden fazla endpoint veya parametre kullanılabilir.
Model Seçimi ve Tahmin: Flask uygulaması içinde desteklenecek her model türü için ayrılmış modüller ya da sınıflar bulunacak. Örneğin, models/lstm_model.py, models/arima_model.py gibi dosyalar ya da bir strateji deseni uygulanarak bir ModelFactory sınıfı ile istenen model nesnesi üretilebilir. Endpoint’e gelen istekte model tipi belirtilmişse (ya da varsayılan bir model varsa), servis ilgili modelin yüklenmesini/çağrılmasını sağlar. Dummy tahmin modunda, bu model çağrıları aslında sabit bir değer dönebilir. Gelişmiş modda ise her model kendi içinde önceden eğitilmiş bir modeli yükleyip predict() yaparak gerçek tahmin üretecektir.
Veri Erişimi: Python servisi tahmin yaparken ihtiyaç duyduğu hisse senedi geçmiş verilerini almalıdır. Bu noktada iki yaklaşım var:
Doğrudan API’den Çekme: Python servisi, gelen istekte belirtilen hisse için TCMB API’sine kendisi çağrı yapıp gereken tarihsel veriyi alabilir. Bu yöntem, servis içinde ek bir istek anlamına gelir ve tahmin süresini biraz uzatabilir, ancak servisi bağımsız kılar (veriye ulaşmak için başka bileşene ihtiyaç duymaz).
Veritabanından Okuma: Alternatif olarak Python servisi de veritabanına erişebilir ve ilgili hissenin geçmiş verisini (örneğin son 100 günlük fiyat) veritabanından sorgulayabilir. Bunun için Python tarafında bir PostgreSQL istemci kütüphanesi (psycopg2 veya SQLAlchemy gibi) kullanılarak okuma yapılabilir. Bu yöntem, veri halihazırda yerel veritabanında olduğu için daha hızlı olabilir ve TCMB API kotasını da zorlamaz. Ancak mikroservis mimarisi açısından bakıldığında, Python servisinin veritabanına erişmesi backend ile daha sıkı bağlılık yaratabilir.
Tercihe bağlı olarak ilk aşamada doğrudan API’den çekmek daha basit olabilir, ilerleyen aşamalarda performans ihtiyacına göre veritabanına erişim eklenebilir. Ayrıca, Python servisi önbellekleme (caching) mekanizmaları da kullanabilir; sık istenen bir hissenin verisini kısa bir süre için bellek içinde tutarak her seferinde kaynaktan çekmeyi önleyebilir.
Tahmin Sonucunun Döndürülmesi: Python servisi tahmin işlemini gerçekleştirdikten sonra sonucu JSON formatında döndürür. Örneğin:
json
Kopyala
{
  "sembol": "GARAN",
  "tahmin_tarihi": "2025-03-15",
  "tahmin_degeri": 12.34,
  "model": "LSTM"
}
gibi bir çıktı üretilebilir. Bu çıktıda tahmin yapılan hisse sembolü, tahminin ait olduğu gelecek tarih (veya dönem), tahmin edilen fiyat veya getiri ve kullanılan model bilgisi yer alır. Bu format, backend tarafından anlaşılıp veritabanına yazılacak ve istemciye iletilecektir.
Hafif ve Ölçeklenebilir Yapı: Flask uygulaması üretim ortamında bir WSGI sunucusu (örneğin gunicorn) ile çalıştırılabilir. Docker konteynerinde bu şekilde çoklu iş parçacığı veya işlem ile ölçeklendirme yapılabilir. İleride yüksek yük altına gireceği düşünülürse, bu Python servisi konteynerden yatay olarak ölçeklendirilebilir (ör. aynı servisten birden çok kopya çalıştırarak, istekleri yük dengeleyici ile dağıtmak).
Ayrıca, Python servisinin kendisine gelen istekleri loglaması, hata durumlarını uygun HTTP kodlarıyla geri bildirmesi (örneğin, sembol bulunamazsa 404, sunucu hatası varsa 500) sağlanacak. Bu, sistemin izlenebilirliği ve hata ayıklaması için önemlidir.
Veritabanı Katmanı (PostgreSQL)
Platformda kullanılacak PostgreSQL veritabanı, hem ham finansal verilerin hem de üretilen tahmin sonuçlarının kalıcı olarak saklanmasını sağlayacak. Veritabanı tasarımında göz önünde bulundurulacaklar:
Finansal Veri Tablosu: Hisse senetlerinin tarihsel fiyat ve belki diğer metriklerini tutmak için bir tablo oluşturulacak (örneğin hisse_fiyat tablosu). Bu tabloda en azından şu alanlar olabilir: sembol (hisse kodu), tarih, acilis_fiyati, kapanis_fiyati, en_yuksek, en_dusuk, hacim gibi günlük bazda veriler. TCMB API’sinden gelen veri hangi detayları içeriyorsa ona göre uyarlanır. Birincil anahtar olarak (sembol, tarih) ikilisi kullanılabilir.
Tahmin Sonuç Tablosu: Model tarafından üretilen tahminleri saklamak için bir tablo (örneğin tahmin_sonuc tablosu) tasarlanacak. Bu tabloda da sembol, tahmin_tarihi (geleceğe yönelik tarih), tahmin_edilen_deger, model_turu, olusturulma_zamani gibi alanlar bulunabilir. Bu sayede hangi modelin ne zaman hangi tahmini yaptığı izlenebilir. Bu tablo zamanla büyüyeceğinden, gerektiğinde periyodik temizleme veya arşivleme stratejisi planlanabilir (örneğin, çok eski tahminler silinebilir ya da ayrı bir arşiv yapısına alınabilir).
Diğer Tablolar: İhtiyaca göre kullanıcı yönetimi (eğer platformda kullanıcı giriş sistemi olacaksa), yetki yönetimi veya API anahtarları gibi konular için ek tablolar olabilir. Örneğin, API kullanımını sınırlamak için kullanici ve api_token tabloları gibi yapılar eklenebilir.
Erişim ve Bağlantı: Spring Boot uygulaması veritabanına JDBC URL’si üzerinden bağlanacak. Bu bağlantı detayları (sunucu adı, port, veritabanı adı, kullanıcı adı, şifre) konfigürasyonda tanımlanır. Geliştirme ve üretim ortamları için farklı ayarlar (örneğin Docker içinde sunucu adı db olacak şekilde) kullanılabilir. Spring Boot üzerinde Connection Pool (HikariCP varsayılan olarak gelir) kullanılarak veritabanı bağlantılarının verimli yönetilmesi sağlanır.
JPA Kullanımı: Eğer JPA/Hibernate kullanılıyorsa, entity sınıfları Spring Boot uygulaması başlarken veritabanındaki tablo yapıları ile eşleşir. Gerekirse DDL otomasyonu (spring.jpa.hibernate.ddl-auto=update gibi) geliştirme aşamasında kullanılabilir, ancak üretimde daha kontrollü bir yaklaşımla manuel migrasyonlar tercih edilmeli. Bu amaçla Liquibase veya Flyway gibi araçlar entegre edilerek veritabanı versiyonlama ve değişiklik yönetimi sağlanabilir. Örneğin, yeni bir tablo eklemek için SQL tanımı bir migrasyon dosyasında tanımlanıp CI/CD sürecinde uygulanabilir.
Veritabanı Performansı: Büyük miktarda finansal veri olabileceği için uygun indekslemeler yapılacak (örneğin sembol ve tarih alanlarında indeks). Sorgular optimize edilecek, belki sık kullanılan raporlar için materialized view veya özet tablolar düşünülecek. Ancak ilk aşamada normalleştirilmiş iki temel tablo (fiyat ve tahmin) yeterli olacaktır.
PostgreSQL konteyneri veri sürekliliği için bir cilt (volume) kullanacak, bu sayede konteyner yeniden başlatılsa da veriler kaybolmayacak. Veritabanı kullanıcı yetkileri düzenlenerek, uygulamanın kullandığı kullanıcıya sadece gerekli izinler verilecek (örneğin sadece kendi şemasında SELECT/INSERT). Ayrıca, hassas bilgiler (db şifresi gibi) Docker Compose dosyasında düz metin tutulmayıp ortam değişkenlerinden veya Docker secret mekanizmasından çekilebilir. Bu da güvenliği artırır.
Konteyner Yönetimi (Docker Compose)
Tüm bileşenlerin uyum içinde tek bir ortamda çalıştırılması için Docker Compose kullanılacaktır. Her bileşen (Spring Boot backend, Python ML servisi, PostgreSQL) ayrı bir Docker imajı/konteyner olarak tanımlanacak ve Compose onları tek bir ağda birleştirip yönetmeyi sağlayacaktır. Docker Compose yapılandırmasının ana hatları:
Dockerfile Tanımları:
Backend için: Proje artefact’ını (ör. .jar dosyası) içeren bir imaj oluşturulacak. Örneğin, OpenJDK 17 tabanlı küçük bir imaj (alpine) kullanılabilir. Dockerfile, uygulamanın jar’ını konteyner içine kopyalayıp çalıştıran bir giriş noktası içerecek.
Python Servisi için: Python tabanlı bir imaj (ör. Python 3.10-slim) kullanılacak. Bu imaj içerisinde gerekli Python bağımlılıkları (Flask, numpy, pandas, scikit-learn vs. modele göre) pip ile yüklenecek ve Flask uygulaması gunicorn ile servise alınacak.
PostgreSQL için: Genellikle doğrudan postgres: resmi imajı kullanılabilir. Bu imaj, gerekli ortam değişkenleri (POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB) sağlandığında otomatik olarak belirtilen kullanıcı ve veritabanıyla ayağa kalkacaktır.
docker-compose.yml İçeriği:
Compose dosyasında her bir servis için tanım olacak: backend, mlservice, db gibi.
backend servisi için:
build: Backend Dockerfile’ının bulunduğu yol.
ports: Dışarıya açılan port (ör. "8080:8080").
environment: Gerekli ortam değişkenleri (örn. SPRING_DATASOURCE_URL=jdbc:postgresql://db:5432/..., SPRING_DATASOURCE_USERNAME=..., SPRING_DATASOURCE_PASSWORD=..., Python servisine erişim için belki ML_SERVICE_URL=http://mlservice:5000 gibi).
depends_on: Bu servis başlamadan önce db ve mlservice servislerinin başlatılması gerektiğini belirtebiliriz.
mlservice servisi için:
build: Python servisinin Dockerfile yolu.
ports: Örneğin "5000:5000" (Flask uygulaması bu portta dinler).
environment: Gerekirse TCMB API anahtarı gibi değişkenler verilebilir (örn. API_KEY=...).
depends_on: Bu servis genellikle veritabanına doğrudan bağlı olmayacak (eğer DB kullanacaksa depends_on db eklenebilir), ama genellikle sadece başlatılabilir.
db servisi için:
image: "postgres:15-alpine" gibi bir imaj.
ports: "5432:5432" (veritabanı portu, geliştirmenin kolay olması için host’ta açılabilir, ancak prod’da gerekmez).
volumes: Veri kalıcılığı için, örneğin db_data:/var/lib/postgresql/data şeklinde adlandırılmış bir cilt kullanılacak.
environment: POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB gibi zorunlu değişkenler.
Tüm servisler aynı özel ağa otomatik olarak alınacak (Docker Compose varsayılan olarak proje adına özel bir network oluşturur). Bu sayede backend konteyneri diğerlerine servis adıyla (hostname) ulaşabilir. Örneğin, backend kodunda veritabanı hostu olarak db kullanmak yeterlidir (DNS çözümü sayesinde).
Başlatma Sırası: depends_on ayarları, konteynerlerin başlatma sırasını ayarlar ama tam olarak kullanım hazır olmasını garanti etmez. Bu nedenle, backend uygulaması başlatıldığında veritabanının hazır olduğunu varsaymamalı, bağlantı hatalarını yönetebilmeli veya bir health check mekanizması eklenebilir. Compose v3'te healthcheck tanımları yapılarak bir servisin sağlıklı olması beklenebilir.
Ortam Değişkenleri ve Yapılandırma: Compose kullanırken, hassas bilgiler docker-compose.yml içinde düz yazılmamalıdır. Geliştirme için basit tutulabilir ancak üretimde .env dosyasından yükleme veya Docker Swarm/Kubernetes secrets mekanizmaları tercih edilebilir. Örneğin, veritabanı şifresi .env dosyasında tanımlanıp compose dosyasında referans verilebilir.
Loglama ve İzleme: Compose tüm servislerin log’larını bir araya getirebildiği için geliştirme sırasında kolay izleme sağlar. Her konteynerin standart çıktısı bir arada takip edilebilir. Uzun vadede, merkezi loglama (ELK stack gibi) veya metrik toplama (Prometheus, Grafana) eklenmek istenirse, bunlar da compose’a yeni servisler olarak eklenebilir.
Docker Compose ile tek komutla (docker-compose up -d) tüm sistem ayağa kaldırılabilecek ve yine tek komutla durdurulabilecektir. Bu, farklı ortamlarda (geliştirme, test, üretim) tutarlı ortam kurulumu sağlar ve "çalışıyor, çalışmıyor" problemlerini en aza indirir. Ayrıca, her bileşen konteyner içinde çalıştığı için, bağımlılık uyumsuzlukları veya "makinemde çalışıyor" sorunları yaşanmaz.
CI/CD Süreçleri
Proje için sürekli entegrasyon ve sürekli dağıtım (CI/CD) süreçleri kurularak, kod değişikliklerinin otomatik olarak test edilip dağıtılması hedeflenmektedir. Bu amaçla GitHub Actions veya Jenkins gibi bir araç kullanılabilir. Temel yaklaşım şu olacaktır:
Versiyon Kontrol ve Trigger: Proje kodu GitHub (veya benzeri) bir repoda tutulacaktır. Repoya her kod gönderimi (push) veya pull request oluşturulduğunda CI süreci tetiklenecek. Örneğin, GitHub Actions kullanılıyorsa, bir workflow YAML dosyası belirli branch’lere push olduğunda devreye girecek şekilde ayarlanır.
Backend CI Pipeline:
Derleme ve Birim Testleri: Pipeline öncelikle Maven/Gradle ile Spring Boot uygulamasını derleyecek ve tüm birim testlerini çalıştıracaktır. Amaç, kodun derlenebilir ve temel testleri geçer durumda olduğunu doğrulamak.
Docker İmajı Oluşturma: Testler başarılıysa, CI süreci otomatik olarak backend için Docker imajını üretecek. Örneğin, docker build -t myorg/stock-backend:${GIT_COMMIT_SHA} komutu ile. İmaj küçük tutulması için çok aşamalı (multi-stage) Dockerfile kullanılarak sadece uygulama jar’ını içeren bir runtime imajı oluşturulur.
İmaj Push (Opsiyonel CI aşaması, genellikle CD parçası): Eğer registry (Docker Hub, AWS ECR vb.) kullanılıyorsa, oluşturulan imaj bu registry’ye push edilir. Bu sayede dağıtım aşaması bu imajı kullanabilir.
(Opsiyonel) Entegrasyon Testleri: CI pipeline, Docker Compose kullanarak tüm sistemi ayağa kaldırıp bazı entegrasyon testleri çalıştırabilir. Örneğin, geçici bir ortamda compose ile backend, mlservice, db başlatılır; ardından test betikleri backend API’sine istek atarak gerçek akışı test eder. Bu, farklı bileşenlerin uyumunu CI aşamasında doğrular. Bu kısım biraz daha kompleks olabilir, ancak kaliteyi ciddi ölçüde artırır.
Python ML Servisi CI Pipeline:
Kod Kalitesi ve Test: PyTest veya unittest ile yazılmış birim testleri çalıştırılır. Ayrıca PEP8 uyumu için bir linter (flake8 gibi) çalıştırmak da faydalı olabilir.
Docker İmajı Oluşturma: Testler başarılı ise Python servisinin Docker imajı üretilir (ör. myorg/stock-mlservice:${GIT_COMMIT_SHA}). Bu imaj da benzer şekilde registry’ye gönderilir.
(Opsiyonel) Entegrasyon Testleri: Tek başına Python servisini test etmek için, Flask uygulaması test modunda çalıştırılıp birkaç örnek API çağrısı yapılarak (örneğin dummy modelin belirli bir girdi için beklenen sabit çıktıyı verdiği kontrolü gibi) entegrasyon testi yapılabilir.
Sürekli Dağıtım (CD): CI aşamaları geçildikten sonra, otomatik dağıtım adımı devreye girebilir. Bu, ortama göre değişir:
Geliştirme/Staging Ortamı: Her başarılı build sonrası otomatik olarak ilgili Docker Compose ortamı güncellenebilir. Örneğin, Jenkins sunucusu, test sunucusunda docker-compose pull && docker-compose up -d komutlarını çalıştırarak en yeni imajları ayağa kaldırır.
Üretim Ortamı: Kod belirli bir versiyona (ör. release tag) ulaştığında manuel onaylı bir pipeline adımıyla üretime alınabilir. Üretimde de yine Docker Compose (veya daha ileri seviye bir orkestrasyon aracı, örn. Kubernetes) kullanılarak konteynerler güncellenir. Mavi-yeşil dağıtım veya kesintisiz güncelleme stratejileri planlanabilir.
Ayrık Pipeline’lar: Backend ve Python servisinin CI/CD süreçleri ayrı olabilir, ancak Docker Compose tüm sistemi kapsadığı için entegrasyon noktaları vardır. Örneğin, backend pipeline’ı kendi imajını üretirken, belki test için sabit bir Python servisi imajı kullanabilir veya tam tersi. Ortak bir entegrasyon testi aşaması yapılacaksa, iki pipeline’ın sonuçlarını birlikte ele alan bir üçüncü adım gerekebilir. Alternatif olarak, tek bir pipeline tüm projeyi bir monorepo gibi ele alabilir. Proje büyüklüğüne ve repo yapısına göre karar verilecektir.
CI/CD sürecinin getirileri:
Her kod değişikliği sonrasında otomatik test ve derleme yapıldığı için hatalar erken yakalanır.
İnsan müdahalesi azalacağı için hatalı konfigürasyon veya unutulan adım riski düşer.
Her şey otomatik olduğundan ekip içinde DevOps kültürü teşvik edilir, teslimatlar hızlanır.
Ayrıca, pipeline içinde güvenlik taramaları (ör. Docker imajları için Trivy taraması, bağımlılık zafiyet taraması) ve kod kalite analizleri (SonarQube gibi) entegre edilebilir, bu da projenin kalitesini ve güvenliğini arttırır.
Test Süreci
Projenin güvenilirliğini sağlamak için kapsamlı bir test stratejisi uygulanacaktır. Testler farklı seviyelerde ele alınacak:
Birim Testleri (Unit Tests): Her birim kodun (metod, sınıf) doğru çalıştığını küçük izolasyonlu testlerle doğrulayan testlerdir.
Spring Boot (Java) Tarafı: JUnit 5 ve Mockito gibi kütüphaneler kullanılarak controller, service ve repository katmanları için birim testleri yazılacak. Örneğin, TahminService için, Python servisine çağrı yapan kısmı Mockito ile taklit ederek (mock) sadece iş mantığının doğru çalıştığını test edebiliriz. Controller’da gelen parametrelerin doğru şekilde service’e iletilip iletilmediği veya hata durumlarının doğru yönetimi test edilebilir. Repository katmanı testlerinde, H2 gibi hafif bir bellek-içi veritabanı kullanarak JPA sorgularının beklendiği gibi çalıştığı kontrol edilebilir.
Python Servisi Tarafı: PyTest çerçevesi ile fonksiyonların çıktıları test edilecek. Örneğin, dummy model fonksiyonu belirli bir girdi için hep aynı çıktıyı veriyorsa, bu senaryo test edilecek. Flask endpoint’leri için de Flask’in test client’ı kullanılarak örnek isteklerin doğru yanıtlar dönüp dönmediği kontrol edilir. Model seçimi mantığı, parametre gelmezse default modelin kullanılması gibi lojikler de birim testlerle doğrulanır.
Entegrasyon Testleri: Sistemin parçalarının birlikte çalışmasını doğrulamak için yapılacak testlerdir.
Spring Boot uygulamasında entegrasyon testi için, Spring Boot Test anotasyonları ile uygulamayı gerçek gibi başlatıp (gerekirse sahte bir Python servisiyle) uçtan uca akış test edilebilir. Örneğin, test sırasında Python servis çağrısı yapan bileşeni override edip önceden tanımlı bir cevap döndürmesini sağlamak (MockRestServiceServer ile sabit JSON döndürmek gibi) ve sonra REST çağrısı sonucunda veritabanına yazı gerçekleşti mi kontrol etmek.
Bir adım ötesi, gerçekten Flask servisini de ayağa kaldırarak test etmek. Bu durumda Docker Compose test profili ile veya Testcontainers gibi kütüphanelerle, test sürecinde gerekli servislerin konteynerlerini başlatıp gerçek iletişimi test etmek mümkün. Örneğin, test başında bir PostgreSQL ve bir Flask konteyneri açılır, Spring Boot testini bu gerçek servislerin adreslerini kullanacak şekilde yapılandırırız (application-test.properties ile). Ardından bir controller çağrısı yaparak tüm akışın (veritabanından okuma, Flask’e çağrı, yanıt alma, kaydetme) beklendiği gibi çalıştığını doğrularız.
Python servisi için de entegrasyon testi olarak, belki gerçek veritabanına bağlanıp (test için özel bir DB veya test verisiyle doldurulmuş) gerçekçi bir tahmin akışı test edilebilir.
Yük ve Performans Testleri: Sistem belirli bir yük altında test edilecek ki hem performans kriterlerini sağlasın hem de olası darboğazlar tespit edilebilsin.
Araç olarak Apache JMeter veya k6 kullanılabilir. Örneğin, JMeter ile aynı anda 1000 tane GET /api/tahmin?sembol=xxx isteği gönderilerek sistemin tepki süresi ölçülür. Bu testler sonucunda backend’in cevap verme süresi, Python servisinin işlem kapasitesi ve veritabanının yük altındaki davranışı gözlenir.
Özellikle makine öğrenmesi servisi CPU yoğun bir iş yapacağı için, onun ölçeklendirme ihtiyacı bu testlerde ortaya çıkabilir. Eğer 1 instance yüksek yükü kaldıramıyorsa, ya daha güçlü bir makine veya birden fazla instance (scale-out) ihtiyacı belirlenir.
Yük testlerinde ayrıca bellek sızıntısı, bağlantı zaman aşımı gibi sorunlar da tespit edilebilir. Örneğin, 1000 istekten sonra uygulama bellek kullanımını bırakmıyorsa bir sorun olabilir, bu da profilleme gerektirir.
Kabul (Acceptance) ve Son Kullanıcı Testleri: Eğer bu platformun bir arayüzü varsa, uçtan uca testler de yapılabilir. Ancak sadece API katmanında düşünürsek, bir QA mühendisi Postman vb. ile farklı senaryoları deneyerek (geçerli istek, hatalı sembol, yetkisiz erişim vs.) sistemin doğru tepkiler verdiğini manuel olarak da test edebilir.
Testler, CI sürecine entegre edileceği için her kod değişikliğinde otomatik koşacak ve kaliteyi sürekli koruyacaktır. Ayrıca, her yeni eklenen özellik için birim test ve gerekiyorsa entegrasyon testleri de eklenerek regression (geri tepme) hatalarının önüne geçilecek.
Güvenlik Önlemleri
Platformun güvenliği, en az fonksiyonalite kadar önemli bir gereksinimdir. Hem uygulama seviyesinde hem de konteyner/dağıtım seviyesinde çeşitli güvenlik önlemleri uygulanacaktır:
API Güvenliği (Kimlik Doğrulama ve Yetkilendirme): Dış dünyaya açılan REST API’lerin korunması için JWT (JSON Web Token) tabanlı kimlik doğrulama kullanılacak. Bu sayede, platformu kullanacak istemciler (örneğin bir frontend arayüz veya mobil uygulama) önce bir giriş yapıp JWT token alacak, ardından her API isteğinin header’ında bu token’ı göndererek işlem yapabilecektir. Spring Boot uygulamasında Spring Security ile JWT filtreleri konularak, gelen isteklerde geçerli token var mı kontrol edilecek. Yetkilendirme açısından, gerekirse roller tanımlanabilir (örn. "USER", "ADMIN" gibi) ve belirli endpoint’lere erişim bunlara göre kısıtlanabilir.
Alternatif olarak OAuth 2.0 desteği düşünülebilir. Eğer kullanıcı yönetimini kendimiz yapmak istemezsek, Google, Keycloak vb. bir sağlayıcı üzerinden OAuth2 ile token alınıp API’lere iletilebilir. Ancak JWT, bağımsız bir çözüm olarak yeterli olacaktır.
Veritabanı Erişim Yetkilendirmesi: Veritabanına doğrudan erişim sadece backend uygulamasına tanınacak şekilde yapılandırılacak. PostgreSQL üzerinde uygulamaya özel bir kullanıcı oluşturulacak ve bu kullanıcıya sadece gerekli şemaya erişim izni verilecek. Böylece, herhangi bir şekilde veritabanına başka bir yoldan erişilse bile hassas diğer bilgilere ulaşılamaz. Ayrıca, veritabanı bağlantı dizesi ve şifre gibi bilgiler konfigürasyonda şifreli veya en azından düz metin olmayan şekilde tutulabilir (örneğin ortam değişkenlerinden geldiği için repoda yazmaz).
Güvenli Kod Geliştirme:
SQL Injection: Spring Data JPA kullanımı sayesinde çoğu SQL sorgusu ORM tarafından derleneceği için parametre enjeksiyonları otomatik korunur (parametreler bind edilir). Eğer herhangi bir dinamik SQL gerekiyorsa, PreparedStatement kullanımı ve gelen input’ların temizlenmesi şart. Ayrıca repository katmanında method adlarına dayalı sorgular kullanılarak SQL injection riski en aza indirgenir.
XSS (Cross-Site Scripting): Platformun kendisi bir API servisi olsa da, eğer bir web arayüzü de içerecekse veya API sonuçları bir webde gösterilecekse, XSS’e karşı önlem alınmalı. Örneğin, Spring tarafında dönen veriler içinde HTML içerik barındırmayacak, istemci tarafında da gerekli önlemler (output encoding) uygulanacak. Temel olarak, sistem hiçbir zaman bir kullanıcının girdiği veriyi filtresiz olarak başka bir kullanıcıya göndermeyecek.
CSRF (Cross-Site Request Forgery): Eğer API’ler bir web arayüzü ile kullanılacaksa ve cookie tabanlı bir oturum yönetimi varsa, CSRF koruması eklenmeli. Spring Security, form tabanlı girişlerde otomatik CSRF token mekanizması sunar. JWT ile stateless bir mimari kullanıyorsak, CSRF riski büyük ölçüde azalır (çünkü tarayıcı cookie’si kullanılmaz), ancak yine de login gibi işlemler için önlemler alınabilir.
Ağ ve İletişim Güvenliği:
Tüm servisler arasındaki iletişim (backend <-> Python servisi, ve kullanıcı <-> backend) şifreli protokoller üzerinden yapılmalıdır. Örneğin, son kullanıcı ile backend iletişimi HTTPS ile sağlanacak (Spring Boot uygulaması bir reverse proxy arkasında ya da kendi TLS sertifikası ile çalışabilir). İç ağda (Docker ağı içinde) çalışan servisler arasındaki trafik fiziksel olarak izole olsa da, gerektiğinde servisler arası TLS de eklenebilir.
Docker Compose ortamında, mlservice ve db servislerinin dış dünyaya portları açılmayabilir (compose’da sadece backend’in 8080 portunu map edip, diğerlerini host’a yayınlamamak mümkün). Böylece Python servisine ve PostgreSQL’e doğrudan dışarıdan erişim engellenir, sadece backend onları kendi ağı üzerinden kullanır. Bu, olası saldırı yüzeyini azaltır.
Container Güvenliği:
Her bir Docker imajı olabildiğince minimal tutulacak. Gereksiz paketler veya araçlar imajdan çıkarılacak ki potansiyel zafiyetler azalır. Örneğin, Java imajı olarak sadece JRE içeren jlink ile minimize edilmiş bir imaj düşünülebilir. Python imajı da slim/alpine tercih edilerek boyut ve saldırı yüzeyi küçültülecek.
Container içinde çalışan uygulamalar root kullanıcısıyla çalışmayacak. Dockerfile içinde uygun bir kullanıcı oluşturup onunla servis başlatılacak. Bu sayede olası bir kaçış durumda root yetkisi ile ana sisteme zarar verme riski azaltılır.
Düzenli olarak imajlar güvenlik taramasından geçirilecek (CI pipeline’da Trivy veya Clair gibi tarayıcılar entegre edilebilir). Yeni güvenlik yamaları yayınlandığında imajlar yeniden build edilerek güncellenecek.
Diğer Önlemler:
Loglarda hassas veri tutmamaya dikkat edilecek (örneğin JWT token veya şifreler loglanmamalı).
Rate limiting uygulanabilir: Özellikle tahmin API’ı yoğun hesaplama yaptığından, kimliği doğrulanmış kullanıcıların bile saniyede çok fazla istek yapması engellenebilir. Bu, olası hizmet engelleme (DoS) saldırılarının etkisini azaltır.
Gerekirse API’ye istek yapan kullanıcılar için bir quota veya ücretlendirme mekanizması düşünülerek, sistemin adil kullanımı sağlanabilir (bu mimarinin dışında bir iş kuralı ama belirtmeye değer olabilir).
Tüm bu güvenlik önlemleri, platformu olası saldırılara ve hatalı kullanımlara karşı daha dayanıklı hale getirecektir. Geliştirme sürecinde de ekip, güvenlik konusunda bilinçli kod geliştirme prensiplerine (Secure Coding Guidelines) uymaya özen gösterecektir.
Modüler ve Ölçeklenebilir Mimari
Yukarıda tasarlanan yapı, modüler ve ölçeklenebilir bir mimariyi ortaya koymaktadır. Her bir bileşenin ayrı geliştirilmesi, dağıtılması ve gerektiğinde bağımsız olarak ölçeklendirilmesi mümkündür:
Modülerlik: Spring Boot backend, Python ML servisi ve PostgreSQL veritabanı birbirlerinden gevşek bağlı (loosely coupled) mikroservisler olarak çalışır. Aralarındaki iletişim iyi tanımlanmış arayüzler (REST API ve veritabanı sorguları) üzerinden gerçekleşir. Bu sayede bir bileşende değişiklik yapmak (örneğin farklı bir ML modeli eklemek veya veritabanını değiştirmek) diğer bileşenleri asgari düzeyde etkiler. Kod bazında da katmanlı mimari (controller-service-repository) ve ayrık paket yapısı, her bölümün ayrı ele alınabilmesini sağlar.
Ölçeklenebilirlik: Trafik arttığında veya daha fazla tahmin talebi geldiğinde, Docker sayesinde her bileşenden birden fazla kopya çalıştırmak mümkün. Örneğin, CPU yoğun Python servisini yatayda 3 kopyaya çıkartıp bir yük dengeleyici ile backend isteklerini dağıtabiliriz. Aynı şekilde backend uygulaması da birden çok instance olarak çalışıp ölçeklenebilir (duruma göre bir API Gateway arkasında). Veritabanı ölçeklendirmesi için de dikey büyütme (daha güçlü bir sunucu) veya okuma işlemleri için replikalar düşünülebilir. Mimarinin bulut üzerinde konteyner orkestrasyon sistemleriyle (Kubernetes, Docker Swarm) uyumlu olması da ileride kolayca ölçeği artırma imkanı tanır.
Bakım Kolaylığı: Kodun anlaşılır ayrıklıkta olması, testlerle desteklenmiş olması ve CI/CD’nin otomatize edilmesi sayesinde bakım süreçleri rahat olacaktır. Yeni bir geliştirici projeye dahil olduğunda, Docker Compose ile tek komutta çalışır bir sistem kurabilir, testleri çalıştırarak güvenle katkı yapabilir. Logların merkezi toplanması ve versiyonlama/migrasyon araçları da işletim sırasında çıkabilecek sorunların daha hızlı giderilmesini sağlar.
Geliştirilebilirlik: Mimari, yeni özelliklerin eklenmesine açık. Örneğin, farklı bir veri kaynağı eklemek istenirse (başka bir API veya veri sağlayıcı), veri akışı bölümüne entegre edilebilir. Yeni bir tahmin modeli eklendiğinde, Python servisine gerekli kod eklenip belki bir iki konfigurasyon değişikliğiyle sisteme katılabilir. Backend’de belki yeni API endpoint’leriyle farklı analizler sunulabilir (örneğin, belirli bir tarih aralığı için tahmin senaryoları gibi).
İzlenebilirlik ve Hata Ayıklama: Ayrı servisler olduğu için her servis kendi içinde izlenebilir. Örneğin, bir sorun çıktığında, sadece Python servisine odaklanıp oradaki loglar incelenebilir. Dağıtık bir yapı olduğu için, gerekiyorsa dağıtık izleme (distributed tracing, örneğin OpenTelemetry) entegre edilerek bir isteğin uçtan uca takibi yapılabilir. Bu da sorunların tespitinde kolaylık sağlar.